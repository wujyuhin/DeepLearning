{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行预处理，训练word2vec模型\n",
    "# 因为后续需要使用w2v,所以需要数据处理方法尽量函数化，方便后续调用\n",
    "# 并进行数据预处理，如下：\n",
    "# 去除停用词，分词，去除标点符号，去除数字，去除空格\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text, stopword=False):\n",
    "    text = re.sub(r'\\d+', '', text)  # 去除数字\n",
    "    text = ' '.join(jieba.cut(text))  # 分词\n",
    "    # 是否停词\n",
    "    if stopword:\n",
    "        text = ' '.join([word for word in text.split() if word not in stopwords])  # 去除停用词\n",
    "    else:\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "\n",
    "# 使用word2vec进行文本预训练，并保存模型\n",
    "def train_word2vec(data,path):\n",
    "    sentences = [text.split() for text in data['review']]\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=3, workers=4)  # 训练模型\n",
    "    # vector_size 词向量的维度\n",
    "    # window 窗口大小\n",
    "    # min_count 词频阈值，小于该值的词将会被过滤掉\n",
    "    # workers 训练的并行数\n",
    "    model.save(path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 定义路径\n",
    "    data_path = '../../data/ChineseNlpCorpus/datasets/ChnSentiCorp_htl_all/ChnSentiCorp_htl_all.csv'\n",
    "    stopwords_path = '../../data/stopwords.txt'\n",
    "    model_path = 'word2vec.model'\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data[['label', 'review']]\n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "    #  # 数据预处理:去除数字、分词\n",
    "    data['review'] = data['review'].apply(preprocess_text)\n",
    "    # 去除处理完后的review为空的行\n",
    "    data = data[data['review'] != '']\n",
    "    # 训练word2vec模型并保存\n",
    "    train_word2vec(data,model_path)\n",
    "    # 保存预处理后的数据\n",
    "    data.to_csv('../data/ChineseNlpCorpus_processed.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-huyq",
   "language": "python",
   "name": "torch-huyq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
